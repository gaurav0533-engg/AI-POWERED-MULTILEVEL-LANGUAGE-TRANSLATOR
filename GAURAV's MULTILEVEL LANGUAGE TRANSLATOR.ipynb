{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-J2hZT88nnhFgXfKnuvAaRdupyMmAyEE","timestamp":1752400625177},{"file_id":"10dgAPk17BQ9oMkyG4ZB_N9xK0xQsZEl5","timestamp":1752400445208}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[" **PROJECT DETAILS**\n","\n",">**AI - POWERED MULTILEVEL LANGUAGE TRANSLATOR**\n","\n","*   **AIM:** Develop a multilevel language translator using AI model capable of understanding and responding in multiple languages for tasks like translation, sentiment analysis, and summarization.\n","\n","\n","\n","*  **PURPOSE:** To bridge language barriers by building a unified NLP model that performs well across diverse languages.\n","\n","\n","\n","\n","___________________________________________________\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Xg5OlzZXFuCv"}},{"cell_type":"markdown","source":["**STEP 1:** IMPORT THE IMPORTANT LIBRARIES\n","\n","__________________________________________________________________________________\n"],"metadata":{"id":"Wz0ppoH3PSBV"}},{"cell_type":"code","source":["import os\n","from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n","import gradio as gr"],"metadata":{"id":"JVvmHs4GKdDs","executionInfo":{"status":"ok","timestamp":1754128039241,"user_tz":-330,"elapsed":73394,"user":{"displayName":"Gaurav Chaurasia","userId":"06040970787821763437"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["**STEP2:** ENVIRONMENT CLEAN-UP\n","\n","________________________________________________________________________________"],"metadata":{"id":"m3Tstsl9RJ3u"}},{"cell_type":"code","source":["os.environ.pop(\"HUGGINGFACE_TOKEN\", None)"],"metadata":{"id":"vNaL7zbrK9xy","executionInfo":{"status":"ok","timestamp":1754128039258,"user_tz":-330,"elapsed":6,"user":{"displayName":"Gaurav Chaurasia","userId":"06040970787821763437"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["**STEP3:** LOAD MODEL AND TOKENIZER\n","\n","_________________________________________________________________________________________"],"metadata":{"id":"jpOd1zmDR1vb"}},{"cell_type":"code","source":["model_name = \"facebook/m2m100_418M\"\n","\n","tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n","model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n"],"metadata":{"id":"cGmhz5aGKi2k","executionInfo":{"status":"ok","timestamp":1754129863059,"user_tz":-330,"elapsed":9886,"user":{"displayName":"Gaurav Chaurasia","userId":"06040970787821763437"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**STEP4:** INFERENCE\n","_________________________________________________________________________________\n","\n"],"metadata":{"id":"G59rlrAqSU3x"}},{"cell_type":"code","source":["def translate(text, src_lang, tgt_lang):\n","    tokenizer.src_lang = src_lang\n","    encoded = tokenizer(text, return_tensors=\"pt\")\n","    generated_tokens = model.generate(\n","        **encoded,\n","        forced_bos_token_id=tokenizer.get_lang_id(tgt_lang)\n","    )\n","    translated = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","    return translated[0]"],"metadata":{"id":"TLws8u7tKquG","executionInfo":{"status":"ok","timestamp":1754128099063,"user_tz":-330,"elapsed":13,"user":{"displayName":"Gaurav Chaurasia","userId":"06040970787821763437"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**STEP5:** DEPOLYMENT\n","\n","_______________________________________________________________________________________"],"metadata":{"id":"T9QgJrC-TNRv"}},{"cell_type":"code","source":["src_langs = [\n","    \"en\",  # English\n","    \"hi\",  # Hindi\n","    \"fr\",  # French\n","    \"de\",  # German\n","    \"es\",  # Spanish\n","    \"zh\",  # Chinese\n","    \"ja\",  # Japanese\n","    \"ko\",  # Korean\n","    \"ar\",  # Arabic\n","    \"ru\",  # Russian\n","    \"pt\",  # Portuguese\n","    \"it\",  # Italian\n","    \"tr\",  # Turkish\n","    \"bn\",  # Bengali\n","    \"ta\",  # Tamil\n","    \"gu\",  # Gujarati\n","    \"ml\",  # Malayalam\n","    \"te\",  # Telugu\n","    \"ur\",  # Urdu\n","    \"fa\",  # Persian\n","    \"id\",  # Indonesian\n","    \"vi\",  # Vietnamese\n","    \"th\",  # Thai\n","    \"pl\",  # Polish\n","    \"uk\",  # Ukrainian\n","    \"nl\",  # Dutch\n","    \"ro\",  # Romanian\n","    \"el\",  # Greek\n","    \"sv\",  # Swedish\n","    \"no\",  # Norwegian\n","    \"fi\",  # Finnish\n","]\n","\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"# GAURAV's MULTILEVEL-LANGUAGE TRANSLATOR\")\n","    with gr.Row():\n","        input_text = gr.Textbox(label=\"ENTER TEXT TO TRANSLATE\")\n","    with gr.Row():\n","        src = gr.Dropdown(choices=src_langs, value=\"English\", label=\"Source Language\")\n","        tgt = gr.Dropdown(choices=src_langs, value=\"Hindi\", label=\"Target Language\")\n","    with gr.Row():\n","        translate_btn = gr.Button(\"TRANSLATE\")\n","    output = gr.Textbox(label=\"TRANSLATION OUTPUT\")\n","\n","    translate_btn.click(translate, inputs=[input_text, src, tgt], outputs=output)\n","\n","demo.launch(share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":680},"id":"1bALJnXHLVtE","executionInfo":{"status":"ok","timestamp":1754128102146,"user_tz":-330,"elapsed":3077,"user":{"displayName":"Gaurav Chaurasia","userId":"06040970787821763437"}},"outputId":"d3d7033f-4bd9-49e1-f196-85fde90bcfef"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gradio/components/dropdown.py:230: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: English or set allow_custom_value=True.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/gradio/components/dropdown.py:230: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: Hindi or set allow_custom_value=True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://77d28522baaa2fe943.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://77d28522baaa2fe943.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["**CHALLENGES AND SOLUTIONS**\n","\n","*   Data imbalance across languages\tUsed data augmentation and sampling techniques to balance dataset.\n","\n","*   Token length variations\tApplied dynamic padding and truncation with attention masks.\n","\n","*   Low performance in low-resource languages\tLeveraged transfer learning and back-translation techniques.\n","\n","\n","*   Inference latency\tOptimized model using ONNX or quantization for faster inference.\n","*   Memory issues during training\tUsed gradient accumulation and mixed-precision training.\n","________________________________________________________________________________________________________\n"],"metadata":{"id":"0CcmTPSBTo-J"}}]}